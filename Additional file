‚úçÔ∏è Writing Tips for Product Specs (ChatGPT-style Applications)

Use these guidelines when drafting product requirement documents, JIRA tickets, prompt instructions, or UX flows for AI chat-based tools.

‚∏ª

‚úçÔ∏è Writing Principles

1. Start with the Problem
	‚Ä¢	Clearly define what problem is being solved and why it matters.
	‚Ä¢	Avoid jumping straight into solutions.

2. Keep Sentences Short and Direct
	‚Ä¢	Use fewer than 30 words per sentence.
	‚Ä¢	Eliminate unnecessary modifiers and redundant phrases.

3. Be Specific and Testable
	‚Ä¢	Ensure every requirement is verifiable and measurable.
	‚Ä¢	Write for QA, not just engineers or stakeholders.

4. Replace Fluff with Data
	‚Ä¢	Avoid adjectives like ‚Äúrobust‚Äù or ‚Äúfast.‚Äù
	‚Ä¢	Provide metrics wherever possible.

5. Eliminate Weasel Words
	‚Ä¢	Avoid vague qualifiers like ‚Äúsome,‚Äù ‚Äúmany,‚Äù or ‚Äúsignificantly.‚Äù
	‚Ä¢	Use precise, supported claims.

6. Avoid Jargon and Explain Acronyms
	‚Ä¢	Spell out acronyms on first use.
	‚Ä¢	Use plain, accessible language.

7. Separate Requirements from Implementation
	‚Ä¢	Define ‚Äúwhat‚Äù before ‚Äúhow.‚Äù
	‚Ä¢	Allow engineering flexibility.

8. Use Active Voice and Assign Ownership
	‚Ä¢	Be explicit about who or what performs each action.
	‚Ä¢	Avoid passive constructions.

9. Use Lists, Tables, and Visual Structure
	‚Ä¢	Organize data clearly with bullets, numbered steps, and tables.
	‚Ä¢	Improve scanability and comprehension.

10. Use Consistent Terms
	‚Ä¢	Stick to one term for each concept across the doc.
	‚Ä¢	Prevent confusion and misalignment.

11. Include Units, Metrics, and Timeframes
	‚Ä¢	Always specify values clearly (e.g., ‚Äú2.5s latency,‚Äù ‚Äú20MB files‚Äù).
	‚Ä¢	Avoid vague timing references like ‚Äúsoon.‚Äù

12. Be Concise, Not Abrupt
	‚Ä¢	Write efficiently but preserve clarity.
	‚Ä¢	Trim filler words and redundancies.

13. Acknowledge Exceptions Thoughtfully
	‚Ä¢	Note when a rule might not apply (e.g., for marketing tone).
	‚Ä¢	Justify deviations with intent.

14. End with Next Steps or Open Questions
	‚Ä¢	Clarify ownership, dependencies, and decisions pending.

‚∏ª

üìò Examples for ChatGPT-style Application Specs

Example 1: Problem-First, Data-Backed

Bad: We want the assistant to be more helpful.

Better: 37% of multi-turn chats fail to resolve the user‚Äôs question. The assistant often ignores prior turns.

‚∏ª

Example 2: Testable, Specific Requirements

Bad: Improve model relevance and response time.

Better:
	‚Ä¢	Return responses within 1.8 seconds p90 latency.
	‚Ä¢	Generate replies rated ‚â•85% relevant in Q3 grounding eval.

‚∏ª

Example 3: Avoid Weasel Words and Hype

Bad: This feature will revolutionize how users interact with AI.

Better: Adding retrieval grounding is projected to reduce hallucination rates by 30% (internal eval 5.3).

‚∏ª

Example 4: Active Voice, Clear Ownership

Bad: An error message is returned if the query is invalid.

Better: The assistant API returns a 400 error with validation details.

‚∏ª

Example 5: Separate Requirement from Solution

Bad: Fine-tune GPT-4 on internal docs.

Better: Assistant must answer 90% of internal queries from document uploads. Solutions may include RAG, fine-tuning, or hybrids.

‚∏ª

Example 6: Use Lists and Structure

Acceptance Criteria:
	‚Ä¢	Response latency ‚â§ 2s (p90)
	‚Ä¢	Shows 3 source documents when grounded
	‚Ä¢	Includes section-level citation metadata

‚∏ª

Example 7: Include Units and Limits

Bad: Keep prompts short.

Better: Ensure system + user + assistant messages remain ‚â§4096 tokens (GPT-4o limit).

‚∏ª

Example 8: UX Flow Detail
	1.	User uploads PDF.
	2.	System parses and embeds sections.
	3.	User types question.
	4.	System retrieves top 3 chunks.
	5.	Assistant replies with inline citations and toggleable sources.

‚∏ª

Example 9: Clarify Decisions and Next Steps

Next Steps:
	‚Ä¢	Define fallback behavior for missing document grounding.
	‚Ä¢	Assign owner for hallucination eval rubric.
	‚Ä¢	Decide whether to display model uncertainty scores to user.
